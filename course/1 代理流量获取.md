# 手把手教你写IAST系列①【代理流量获取】

> 本章节你需要了解Python和Redis，将学习到：
>
> 1. 为什么使用mitmproxy作为前置代理
>
> 2. 如何使用mitmproxy，并进行流量预处理

相关文章：

《巧用 IAST摸鱼》

## 声明

本系列教程仅从个人实践出发，之前文章提及的内容，后续可能不会再详细说明。

## 前言

Web应用安全测试，通常需要拿到Web流量才能进行测试，而安全测试人员一般都是通过代理工具获取流量（其它不是一般情况的不在本次讨论范围）。

常用的代理工具就多样化了，有仅获取流量的，如：自己写一个代理、fiddler、charles；有获取流量后能够手工完成多种测试， 如：burpsuite；有能获取流量并进行安全扫描的，如：xray。

其次，现有安全测试大多数只有安全团队的进行，非安全人员想进行安全测试，需要经过比较多的步骤，先了解安全知识，再学习安全工具，最后上手测试。但是术业有专攻，能不能在不改变现有情况下，非安全人员能够直接进行安全测试？

既然已经有各个类型的工具了，也有能够获取流量进行安全扫描的，为什么还要自己写一个？

可以从后续教程及文章中找到答案。

## 需求分析

稍微整理一下，IAST需要满足以下需求：

1. 能够获取任意Web应用的流量（HTTP/HTTPS）进行安全扫描；最好能够同时检测未授权访问，水平/垂直越权。
2. 非安全人员在不学习安全知识的前提下，也能够正常使用，如QA，程序等。
3. 需要隔离不同项目的用户数据。
4. 可以针对不同的环境，配置不同的代理。

## 前置知识

完成整个系列教程，需要懂一点点：Python、Java、Golang、React、Docker及Docker compose、Redis

完成本章节，只需要懂一点点：Python、Docker及Docker compose、Redis

## 选用代理
在代理选择阶段，一开始是想直接用burpsuite，有代理又有安全扫描，之后发现了棘手的问题，burpsuite需要在图形界面下运行（后续验证可以在命令行运行），也就是大概率要有个Windows server，且不能很好的维护代理和扫描；如果是基于burpsuite魔改，差不多就是整了个企业版的burpsuite。

直接选择现有开源方案也是需要再去魔改，最后其实发现跟自己写的难度差不多。

最终选择选择了[mitmproxy](https://mitmproxy.org/)作为前置代理，用于流量获取和流量前置处理：去重，过滤，标准化等操作。

## 如何使用mitmproxy获取Web流量
官方给出了[三种方式](https://docs.mitmproxy.org/stable/#3-powerful-core-tools)拦截获取Web流量：[mitmproxy](https://docs.mitmproxy.org/stable/#mitmproxy)、[mitmweb](https://docs.mitmproxy.org/stable/#mitmweb)、[mitmdump](https://docs.mitmproxy.org/stable/#mitmdump)，我们需要获取并操作流量，所以选择了mitmdump，使用[Addons](https://docs.mitmproxy.org/stable/addons-overview/)对流量进行额外操作，更多[官方例子](https://docs.mitmproxy.org/stable/addons-examples/)。

安装步骤：[官方Installation](https://docs.mitmproxy.org/stable/overview-installation/)（不建议），[官方Advanced Installation](https://docs.mitmproxy.org/stable/overview-installation/#advanced-installation)（推荐），[官方Docker Images](https://docs.mitmproxy.org/stable/overview-installation/#docker-images)（不建议）

推荐使用Advanced Installation即`pipx`方式安装，方便后续注入其它依赖包（Python packages）。

### 官方[Addons Demo](https://docs.mitmproxy.org/stable/addons-overview/)

1. 安装mitmproxy之后（同时需要安装python ）

2. 以下代码保存成`anatomy.py`：

```python
"""
Basic skeleton of a mitmproxy addon.

Run as follows: mitmproxy -s anatomy.py
"""
import logging


class Counter:
    def __init__(self):
        self.num = 0

    def request(self, flow):
        self.num = self.num + 1
        logging.info("We've seen %d flows" % self.num)


addons = [Counter()]
```

3. 之后使用`mitmdump`运行`mitmdump -s ./anatomy.py`

   会提示：`HTTP(S) proxy listening at *:8080.`

   ![1-1 官方例子](./pics/1-1 官方例子.png)

4. 浏览器代理设置成`127.0.0.1:8080`

5. 访问`mitm.it`，并安装证书。

   ![1-2 证书](./pics/1-2 证书.png)

6. 随便访问一个https的网站，可以看到流量

   ![1-3 bing](./pics/1-3 bing.png)

至此，我们已经能够获取Web应用HTTPS流量。

### 问题及解决方案

按照官方例子，已经能够获取HTTP(S)流量，但用于安全扫描还有以下问题：

1. 流量处理是同步方式执行，如果增加额外耗时操作，用户端将受很大影响；使用异步处理。
2. 直接处理流量会篡改用户数据；需要镜像流量。
3. 会记录预期外的流量，安全扫描会造成误伤；增加域名/IP目标判断。
4. 没有对流量进行去重，短时间内会有大量重复流量；对请求进行标准化处理去重。
5. 记录了静态资源；增加静态资源判断，或者判断content type。
6. 记录了不可达的页面，如404；增加状态码判断。
7. 流量打印到终端，无法进行后续处理；保存流量到Redis或MQ（rabbitmq/kafka）。
8. 需要根据接口，响应页面关键词等方式排除接口；黑名单。
9. 需要仅检测指定接口的功能；白名单。
10. 代理没有账号密码，所有人都可以访问；增加账号密码，使用[proxyauth](https://docs.mitmproxy.org/stable/concepts-options/#proxyauth)选项解决。
11. 多个用户使用同一个代理；不同用户启用不同代理。
12. 需要一个配置文件功能，可以使用文件保存（不利于修改和后续处理），也可以直接保存到Redis中。
13. 需要根据HTTP方法指定检测的流量。

有些问题必须要在前置代理解决，如：1、2、3、4、5、6、7、8、10、13，剩余的可在后续阶段解决。

### 解决问题-核心代码 

>  假设已经按照 [官方Advanced Installation](https://docs.mitmproxy.org/stable/overview-installation/#advanced-installation)进行安装

向`mitmproxy`注入依赖，如果有其它依赖，也可以按照这个方式注入

```shell
pipx inject mitmproxy rtoml
```

总体思路按照问题解决方案来进行。

**url参数值标准化，以get方法为例**

```python
# 将url中的参数值标准化
def params_standardised_default_v(param):
    if '=' in param:
        key = param.split('=')[0]
        value = param.split('=')[1]
        if isinstance(value, int):
            value = 1
        elif isinstance(value, str):
            value = 'a'
        else:
            value = 'b'
        param = key + '=' + value
    return param
```

**判断key在/不在目标数组里**

正则版本也基本类似

```python
def check_not_contains(data: [], key: str):
    if len(data) != 0:
        if key not in data:
            return True
    return False

def check_contains(data: [], key: str):
    if len(data) != 0:
        if key in data:
            return True
    return False
```

**流量去重**

`http_method + standard_url + port + username`作为redis去重的key。

```python
async def data_to_redis(data, redis_con, ttl, standard_set_value):
    request_host = data["request_host"]
    redis_key = "target:" + request_host
    redis_host_key = "flow:" + request_host
    if "username" in data:
        redis_key += "_" + data["username"]
        redis_host_key += "_" + data["username"]
    standard_md5 = hashlib.md5(standard_set_value.encode(encoding='utf-8')).hexdigest()
    target_exist = redis_con.sadd(redis_key, standard_md5)
    redis_con.expire(redis_key, ttl)
    if target_exist == 1:
        redis_con.lpush(redis_host_key, json.dumps(data))
```

详细代码可以参考github

### 运行方式

详细代码可以参考github的README

## 运行截图

### 不区分用户

Redis 流量

![1-4 redis1](./pics/1-4 redis1.png)

### 区分用户

Redis 流量

![1-4 redis2](./pics/1-4 redis2.png)

**流量详情**

```json
{
    "username": "test",
    "raw_url": "https://www.msn.cn/pcs/api/widget/bingHomepage/widgetfeed?cm=zh-cn",
    "scheme": "https",
    "http_version": "HTTP/2.0",
    "method": "GET",
    "port": 443,
    "request_host": "www.msn.cn",
    "project": "project1",
    "response_code": 200,
    "header": {
        "sec-ch-ua": "\"Google Chrome\";v=\"113\", \"Chromium\";v=\"113\", \"Not-A.Brand\";v=\"24\"",
        "sec-ch-ua-mobile": "?0",
        "user-agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/113.0.0.0 Safari/537.36",
        "sec-ch-ua-platform": "\"macOS\"",
        "accept": "*/*",
        "origin": "https://cn.bing.com",
        "sec-fetch-site": "cross-site",
        "sec-fetch-mode": "cors",
        "sec-fetch-dest": "empty",
        "referer": "https://cn.bing.com/",
        "accept-encoding": "gzip, deflate, br",
        "accept-language": "zh-CN,zh;q=0.9,en;q=0.8",
        "cookie": "USRLOC=;MUID=076E004717A5642B2476110216AD6589"
    },
    "url_parameter": "cm=zh-cn",
    "split_url": "https://www.msn.cn/pcs/api/widget/bingHomepage/widgetfeed"
}
```

至此，我们已经能够通过代理获取目标Web流量，并在前置代理阶段对流量进行预处理。

## 优化空间

1. 直接用运行，无法应对复杂的环境。
2. 配置写在配置文件，修改配置需要重启，不够灵活。

后续教程中，将解决遗留的问题，并参考优化空间进行优化。
